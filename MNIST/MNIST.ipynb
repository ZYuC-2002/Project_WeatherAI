{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision as TV\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看是用cuda還是cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 3801716.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 30337013.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 3080117.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST/MNIST\\raw\n",
      "\n",
      "Number of samples in train_data is:  60000\n",
      "Number of samples in test_data is:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = TV.datasets.MNIST(\"data/\", train=True, transform=None,target_transform=None,download=True) #下載並匯入MNIST訓練資料\n",
    "test_data = TV.datasets.MNIST(\"data/\", train=False, transform=None,target_transform=None,download=True) #下載並匯入MNIST測試資料\n",
    "\n",
    "print('Number of samples in train_data is: ',len(train_data))\n",
    "print('Number of samples in test_data is: ',len(test_data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看第一張圖片長什麼樣子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = train_data.data[0] #讀取訓練集中的第一張圖片\n",
    "plt.imshow(x) #把圖片顯示出來\n",
    "print(x.size()) #顯示圖片大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''model layers'''\n",
    "        super(CNN, self).__init__()\n",
    "        # image shape: 1*28*28 (1: one color channel)\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3,3))\n",
    "        # output shape: 1*26*26 \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3,3))\n",
    "        # output shape: 1*24*24\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        '''fully connected layers'''\n",
    "        self.fc = nn.Linear(5408, 10) # 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # model structure\n",
    "        x = self.conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        output = F.log_softmax(x, dim=1) # log prob for numerical stability\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epochs, log_interval):\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Clear gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            output = model(data)\n",
    "\n",
    "            # Negative log likelihood loss (log prob + nll loss = prob + cross entropy loss)\n",
    "            loss = F.nll_loss(output, target)\n",
    "\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log training info\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad(): # disable gradient calculation for efficiency\n",
    "        for data, target in test_loader:\n",
    "            # Prediction\n",
    "            output = model(data)\n",
    "\n",
    "            # Compute loss & accuracy\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() # how many predictions in this batch are correct\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # Log testing info\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.392644\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.163820\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.603842\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.431673\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.338834\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.299587\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.264885\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.396873\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.654762\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.285422\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.300526\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.214831\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.261118\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.156759\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.278894\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.342075\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.375385\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.281500\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.465081\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.370751\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.254219\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.245412\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.309752\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.474750\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.176376\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.410460\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.297839\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.118096\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.147437\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.278253\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.264425\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.094139\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.135714\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.220407\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.064793\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.159068\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.377309\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.337911\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.080941\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.205302\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.117995\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.147725\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.364314\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.115685\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.135414\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.107407\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.103483\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.215161\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.179646\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.237329\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.254299\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.262192\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.240573\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.064223\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.093531\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.223262\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.194137\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.130302\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.271357\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.149835\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.121645\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.085893\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.150000\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.091937\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.141363\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.088984\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.078976\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.142590\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.231676\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.148367\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.202670\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.250331\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.199989\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.281727\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.209451\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.079138\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.156883\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.090776\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.075359\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.179128\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.159247\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.069586\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.031825\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.193793\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.065173\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.109781\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.058393\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.109129\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.102169\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.033413\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.171389\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.068748\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.015010\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.006933\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.093687\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.107074\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.122579\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.093854\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.077765\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.032231\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.071260\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.184765\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.193591\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.185576\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.220901\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.090246\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.071909\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.027533\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.190628\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.120074\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.183754\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.070107\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.111267\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.079432\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.107476\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.103500\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.077668\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.186231\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.033598\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.176269\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.124080\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.023199\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.037146\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.114355\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.119689\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.093509\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.034064\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.171686\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.057472\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.059238\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.177256\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.140084\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.016836\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.041575\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.049414\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.083106\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.214510\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.045713\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.102465\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.062292\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.049006\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.085734\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.064564\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.095363\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.124845\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.152005\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.086276\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.016920\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.060568\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.224467\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.127653\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.037605\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.109802\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.159466\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.112618\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.009017\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.086538\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.108941\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.140156\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.057952\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.054268\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.112649\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.143917\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.039713\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.200976\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.189493\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.185253\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.145742\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.078969\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.092128\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.098660\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.049631\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.131548\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.069588\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.118940\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.028355\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.021089\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.218959\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.075980\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.066000\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.059878\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.114167\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.077216\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.035281\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.104687\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.034649\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.002123\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.011433\n",
      "\n",
      "Test set: Average loss: 0.0863, Accuracy: 9722/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Training settings\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 2\n",
    "    LOG_INTERVAL = 10\n",
    "\n",
    "    # Define image transform\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)) # mean and std for the MNIST training set\n",
    "    ])\n",
    "\n",
    "    # Load dataset\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    test_dataset = datasets.MNIST('./data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Create network & optimizer\n",
    "    model = Net()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Train\n",
    "    train(model, train_loader, optimizer, EPOCHS, LOG_INTERVAL)\n",
    "\n",
    "    # Save and load model (for reference in case you are separating train and test files)\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "    model = Net()\n",
    "    model.load_state_dict(torch.load(\"mnist_cnn.pt\"))\n",
    "\n",
    "    # Test\n",
    "    test(model, test_loader)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
